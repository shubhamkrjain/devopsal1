{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "argp = argparse.ArgumentParser()\n",
    "argp.add_argument(\"-i\", \"--input\", required=True)\n",
    "argp.add_argument(\"-o\", \"--output\", required=True)\n",
    "argp.add_argument(\"-m\", \"--mask-rcnn\", required=True)\n",
    "argp.add_argument(\"-c\", \"--confidence\", type=float, default=0.5)\n",
    "argp.add_argument(\"-t\", \"--threshold\", type=float, default=0.3)\n",
    "argument = vars(argp.parse_args())\n",
    "labelsPath = os.path.sep.join([argument[\"mask_rcnn\"],\n",
    "    \"object_detection_classes_coco.txt\"])\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
    "np.random.seed(42)\n",
    "COLORS = np.random.randint(6, 255, size=(len(LABELS), 3),\n",
    "    dtype=\"uint8\")\n",
    "weightsPath = os.path.sep.join([argument[\"mask_rcnn\"]])\n",
    "configPath = os.path.sep.join([argument[\"mask_rcnn\"],])\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"**************welcome to social distancing security survillance ***************\")\n",
    "print(\"*******************************************************************************\")\n",
    "print(\"\\n\\n\\n*********************please wait system is loading **********************\\n\\n\")\n",
    "net = cv2.dnn.readNetFromTensorflow(weightsPath, configPath)\n",
    "vs = cv2.VideoCapture(argument[\"input\"])\n",
    "writer = None\n",
    "try:\n",
    "    prop = cv2.cv.CV_CAP_PROP_FRAME_COUNT if imutils.is_cv2() \t\telse \n",
    "cv2.CAP_PROP_FRAME_COUNT\n",
    "    total = int(vs.get(prop))\n",
    "    print(\"************Systrm get the video examine the frames***********************\\n\")\n",
    "    print(\":---->Total {} frames in the video /n/n\".format(total))\n",
    "except:\n",
    "    print(\"can't find the frames in videos\")\n",
    "    total = -1\n",
    "while True:   \n",
    "    dist = []    \n",
    "    (grabbed, frame) = vs.read()\n",
    "    if not grabbed:\n",
    "        break\n",
    "    blob = cv2.dnn.blobFromImage(frame, swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    start = time.time()\n",
    "    (boxes, masks) = net.forward([\"detection_out_final\",\n",
    "        \"detection_masks\"])\n",
    "    end = time.time()\n",
    "    for i in range(0, boxes.shape[2]):\n",
    "        classID = int(boxes[0, 0, i, 1])\n",
    "        confidence = boxes[0, 0, i, 2]\n",
    "        if confidence > args[\"confidence\"]:\n",
    "\t\t\t(H, W) = frame.shape[:2]\n",
    "\t\t\tbox = boxes[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
    "\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\t\t\tboxW = endX - startX\n",
    "\t\t\tboxH = endY - startY\n",
    "\t\t\tmask = masks[i, classID]\n",
    "\t\t\tmask = cv2.resize(mask, (boxW, boxH),\n",
    "\t\t\t\tinterpolation=cv2.INTER_NEAREST)\n",
    "\t\t\tmask = (mask > argument[\"threshold\"])\n",
    "\t\t\troi = frame[startY:endY, startX:endX][mask]\n",
    "\t\t\tcolor = COLORS[classID]\n",
    "\t\t\tblended = ((0.4 * color) + (0.6 * roi)).astype(\"uint8\")\n",
    "\t\t\tframe[startY:endY, startX:endX][mask] = blended\n",
    "\t\t\tcolor = [int(c) for c in color]\n",
    "\t\t\tdist.append([startX, startY])\n",
    "\t\t\ttext = \"{}: {:.4f}\".format(LABELS[classID], confidence)\n",
    "\t\t\tcv2.putText(frame, text, (startX, startY - 5),\n",
    "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\t\t\tif classID ==0:\n",
    "\t\t\t\tcv2.rectangle(frame, (startX, startY), (endX, endY),\n",
    "\t\t\t\t\tcolor, 2)                \n",
    "\t\t\t\tfor m in range(0,i+1):\n",
    "\t\t\t\t\tfor n in range(0,1):\n",
    "\t\t\t\t\t\tc1 = dist[i][n]\n",
    "\t\t\t\t\t\tc2 = dist[i][n+1]\n",
    "\t\t\t\t\t\tc3 = dist[m][n]\n",
    "\t\t\t\t\t\tc4 = dist[m][n+1]\n",
    "\t\t\t\t\t\tr =  (c3-c1)*(c3-c1)\n",
    "\t\t\t\t\t\te =  (c4-c2)*(c4-c2)                    \n",
    "\t\t\t\t\t\tz=r+e\n",
    "\t\t\t\t\t\tsq = math.sqrt(z)\n",
    "\t\t\t\t\t\tif sq<=100:\n",
    "\t\t\t\t\t\t\tcv2.line(frame,(c1,c2),(c3,c4),(0,0,255),2)\n",
    "\tif writer is None:\n",
    "\t\tfourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "\t\twriter = cv2.VideoWriter(argument[\"output\"], fourcc, 30,\n",
    "\t\t\t(frame.shape[1], frame.shape[0]), True)\n",
    "\t\tif total > 0:\n",
    "\t\t\telap = (end - start)\n",
    "\t\t\tprint(\"first frame take this much of time: {:.4f} seconds\".format(elap))\n",
    "\t\t\tprint(\"Total time to complete this process: {:.4f}\".format(\n",
    "\t\t\t\telap * total))\n",
    "\twriter.write(frame)\n",
    "print(\"Now go to the file #output and check the file you got video\")\n",
    "print(\"************************************WORK DONE**********************************\")\n",
    "writer.release()\n",
    "vs.release()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
